---
---

@inproceedings{seo-etal-2021-attend,
    title = "Attend What You Need: Motion-Appearance Synergistic Networks for Video Question Answering",
    author = "Ahjeong Seo  and
      Gi-Cheon Kang  and
      Joonhan Park  and
      Byoung-Tak Zhang",
    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers) (ACL 2021),",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.acl-long.481",
    doi = "10.18653/v1/2021.acl-long.481",
    pages = "6167--6177",
    selected={true},
    abstract = "Video Question Answering is a task which requires an AI agent to answer questions grounded in video. This task entails three key challenges: (1) understand the intention of various questions, (2) capturing various elements of the input video (e.g., object, action, causality), and (3) cross-modal grounding between language and vision information. We propose Motion-Appearance Synergistic Networks (MASN), which embed two cross-modal features grounded on motion and appearance information and selectively utilize them depending on the question{'}s intentions. MASN consists of a motion module, an appearance module, and a motion-appearance fusion module. The motion module computes the action-oriented cross-modal joint representations, while the appearance module focuses on the appearance aspect of the input video. Finally, the motion-appearance fusion module takes each output of the motion module and the appearance module as input, and performs question-guided fusion. As a result, MASN achieves new state-of-the-art performance on the TGIF-QA and MSVD-QA datasets. We also conduct qualitative analysis by visualizing the inference results of MASN.",
    pdf = {https://aclanthology.org/2021.acl-long.481/},
    code = {https://github.com/ahjeongseo/MASN-pytorch},
    preview = {acl2021.png}
}

@inproceedings{choi2021dramaqa,
  title={Dramaqa: Character-centered video story understanding with hierarchical qa},
  author={Seongho Choi  and
       Kyoung-Woon On  and
       Yu-Jung Heo  and
       Ahjeong Seo  and
       Youwon Jang  and
       Minsu Lee  and
       Byoung-Tak Zhang},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence (AAAI 2021),},
  volume={35},
  number={2},
  pages={1166--1174},
  month= feb,
  year={2021},
  selected={true},
  pdf = {https://arxiv.org/abs/2005.03356},
  code = {https://github.com/liveseongho/DramaQA},
  site = {https://dramaqa.snu.ac.kr/},
  preview = {aaai2021.png}
}

@article{서아정2019순차,
  title={Sparse Self-Attention Mechanism for Learning Sequential Video Data},
  author={Ahjeong Seo  and
      Kyoung-Woon On  and
      Byoung-Tak Zhang},
  journal={Korea Software Congress 2019 (KSC 2019),},
  pages={539--541},
  month=dec,
  year={2019},
  selected={true},
  pdf = {https://bi.snu.ac.kr/Publications/Conferences/Domestic/KSC2019/KSC2019_AJSeoOZ.pdf},
  code = {https://github.com/ahjeongseo/SparseSelfAttention},
  preview = {ksc2019.png}
}
